# Gemini_Connect
This is the official repository for my submission to the Kaggle Gemini Long Context Challenge. <br>
Submission Notebook: https://www.kaggle.com/code/ariondas/iiit-ranchi-gemini-long-context-challenge <br>

I try to show a use-case of the long context Gemini's new models (as of 2nd December, 2024) provide. I try to utilize the long context the aforementioned models provide to come up with related papers to a particular topic. Hopefully, it helps us fellow researchers. <br>

---

Here are a few plots to highlight the models' performance: 
### Related Papers Plot: 
<p align='center'>
 <img src="https://github.com/user-attachments/assets/7673056e-18e1-423e-949b-581e315300fd", width="500" />
</p>

---

### Maximum Tokens Limit across models: 
<p align='center'>
 <img src="https://github.com/user-attachments/assets/e2d5da41-6fb5-4afb-8c00-042aa113ea35", width="500" />
</p>

---

### Time taken to generate responses: 
<p align='center'>
 <img src="https://github.com/user-attachments/assets/1d67497a-3826-4d58-a5c8-f167b17b139a", width="500" />
</p>

---
### REPORT
The Gemini-1.5 model variants claim upwards of 1 million context length (Gemini-1.5-pro claims 2 million). But, how do they fair in practise? I have prepared a report on my observations. All the details of my experiments are added to this report:

<p align='center'>
 <img src="https://github.com/user-attachments/assets/15af7176-b227-4f2c-8ea5-fa95ab756665", width="500" />
</p>

[Report](https://drive.google.com/file/d/1W3hqhKaVvVbcDdJ4cYCOFGLzj5juUSTD/view?usp=sharing)

---

I have also summarized the entire work in this video: 

https://github.com/user-attachments/assets/edca3f7d-c611-41f0-895b-9c280698979c

---
